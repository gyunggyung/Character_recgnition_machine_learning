{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "# scipy.special for the sigmoid function expit()\n",
    "import scipy.special\n",
    "# library for plotting arrays\n",
    "import matplotlib.pyplot\n",
    "# ensure the plots are inside this notebook, not an external window\n",
    "%matplotlib inline\n",
    "# helper to load data from PNG image files\n",
    "import scipy.misc\n",
    "# glob helps select multiple files using patterns\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        self.wih = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)\n",
    "\n",
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"../csv/mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 10\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift the inputs\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ... my_own_images/2828_my_own_image.png\n",
      "min =  0.01\n",
      "max =  1.0\n",
      "[[ 0.00091782]\n",
      " [ 0.07322102]\n",
      " [ 0.1740442 ]\n",
      " [ 0.00131163]\n",
      " [ 0.01023995]\n",
      " [ 0.01569551]\n",
      " [ 0.13244178]\n",
      " [ 0.02920034]\n",
      " [ 0.07288273]\n",
      " [ 0.00207174]]\n",
      "network says  2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5e8b3250f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the neural network withour own images\n",
    "\n",
    "# load image data from png files into an array\n",
    "print (\"loading ... my_own_images/2828_my_own_image.png\")\n",
    "img_array = scipy.misc.imread('my_own_images/8.png', flatten=True)\n",
    "    \n",
    "# reshape from 28x28 to list of 784 values, invert values\n",
    "img_data  = 255.0 - img_array.reshape(784)\n",
    "    \n",
    "# then scale data to range from 0.01 to 1.0\n",
    "img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "print(\"min = \", numpy.min(img_data))\n",
    "print(\"max = \", numpy.max(img_data))\n",
    "\n",
    "# plot image\n",
    "matplotlib.pyplot.imshow(img_data.reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "# query the network\n",
    "outputs = n.query(img_data)\n",
    "print (outputs)\n",
    "\n",
    "# the index of the highest value corresponds to the label\n",
    "label = numpy.argmax(outputs)\n",
    "print(\"network says \", label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
